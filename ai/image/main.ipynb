{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"umitka/chest-x-ray-balanced\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2925ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04d51ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(path))\n",
    "print(os.listdir(f\"{path}/chest_xray_balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path + \"/chest_xray_balanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e261e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f\"{path}/train\"\n",
    "test_dir = f\"{path}/test\"\n",
    "val_dir = f\"{path}/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((288, 288)),\n",
    "        transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((288, 288)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d13fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\n",
    "    root=train_dir,\n",
    "    target_transform=None,\n",
    "    transform=data_transforms,\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    target_transform=None,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "val_data = datasets.ImageFolder(\n",
    "    root=val_dir,\n",
    "    target_transform=None,\n",
    "    transform=test_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset=val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_data[0]\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35804fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b2(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2140e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.features.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "for layer in list(model.features.parameters())[:-7]:\n",
    "    layer.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    [\n",
    "        nn.Dropout(p=0.4, inplace=True),\n",
    "        nn.Linear(in_features=1408, out_features=1, bias=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([1, 3, 288, 288]).to(device)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": model.features.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 5e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    return correct / len(y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "results_path = \"./chest_xray_results\"\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "\n",
    "with open(f\"{results_path}/class_names\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5831e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 3\n",
    "early_stop = 0\n",
    "best_loss = None\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"{results_path}/runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Epochs\"):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in tqdm(\n",
    "        enumerate(train_data_loader),\n",
    "        total=len(train_data_loader),\n",
    "        desc=f\"Training epoch {epoch}\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        y = y.unsqueeze(dim=1).float()\n",
    "        loss = loss_fn(logits, y)\n",
    "        y_pred = torch.round(torch.sigmoid(logits))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc_fn(y, y_pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_data_loader)\n",
    "    train_acc /= len(train_data_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in tqdm(\n",
    "            enumerate(val_data_loader),\n",
    "            total=len(val_data_loader),\n",
    "            desc=f\"Validating epoch {epoch}\",\n",
    "            leave=False,\n",
    "        ):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            y = y.unsqueeze(dim=1).float()\n",
    "            loss = loss_fn(logits, y)\n",
    "            y_pred = torch.round(torch.sigmoid(logits))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc_fn(y, y_pred)\n",
    "\n",
    "        val_loss /= len(val_data_loader)\n",
    "        val_acc /= len(val_data_loader)\n",
    "\n",
    "    writer.add_scalars(\n",
    "        main_tag=\"Loss\",\n",
    "        tag_scalar_dict={\"train_loss\": train_loss, \"val_loss\": val_loss},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "\n",
    "    writer.add_scalars(\n",
    "        main_tag=\"Accuracy\",\n",
    "        tag_scalar_dict={\"train_acc\": train_acc, \"val_acc\": val_acc},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "\n",
    "    writer.add_scalar(\n",
    "        tag=\"Learning Rate\",\n",
    "        scalar_value=optimizer.param_groups[0][\"lr\"],\n",
    "        global_step=epoch,\n",
    "    )\n",
    "\n",
    "    info = (\n",
    "        f\"Epoch: {epoch} | \"\n",
    "        f\"Train acc: {train_acc:.5f} | Train loss: {train_loss:.5f} | \"\n",
    "        f\"Val acc: {val_acc:.5f} | Val loss: {val_loss:.5f}\"\n",
    "    )\n",
    "\n",
    "    print(info)\n",
    "    with open(f\"{results_path}/training_info.txt\", \"a\") as f:\n",
    "        f.write(info + \"\\n\")\n",
    "\n",
    "    old_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning rate reduced: {old_lr} â†’ {new_lr} at epoch {epoch}\")\n",
    "\n",
    "    if best_loss is None or val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model, f\"{results_path}/model.pth\")\n",
    "        print(f\"Best model saved after epoch: {epoch}\")\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == patience:\n",
    "            print(f\"Early stopping after epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"{results_path}/model.pth\", weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "test_preds = []\n",
    "model.eval()\n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch, (X, y) in tqdm(\n",
    "        enumerate(test_data_loader),\n",
    "        total=len(test_data_loader),\n",
    "        desc=f\"Testing\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        y = y.unsqueeze(dim=1).float()\n",
    "        loss = loss_fn(logits, y)\n",
    "        y_pred = torch.round(torch.sigmoid(logits))\n",
    "        test_preds.append(y_pred.cpu())\n",
    "        test_loss += loss.item()\n",
    "        test_acc += acc_fn(y, y_pred)\n",
    "\n",
    "    test_loss /= len(test_data_loader)\n",
    "    test_acc /= len(test_data_loader)\n",
    "\n",
    "test_preds = torch.cat(test_preds)\n",
    "test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e96707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(task='binary', num_classes=len(class_names))\n",
    "conf_mat = cm(test_preds.squeeze(), torch.Tensor(test_data.targets).type(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb05b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=conf_mat.numpy(), class_names=class_names, figsize=(7, 7)\n",
    ")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.savefig(f\"{results_path}/confusion_matrix.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "torch.save(model, f\"{results_path}/cpu_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40112418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "with open(f\"{results_path}/classification_report.txt\", \"w\") as f:\n",
    "    f.write(\n",
    "        str(\n",
    "            classification_report(\n",
    "                torch.Tensor(test_data.targets).type(torch.int64), test_preds\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "report = classification_report(\n",
    "    torch.Tensor(test_data.targets).type(torch.int64), test_preds\n",
    ")\n",
    "pprint(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
